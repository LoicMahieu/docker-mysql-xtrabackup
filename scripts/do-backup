#!/usr/bin/env node

const format = require('date-fns/format')
const parse = require('date-fns/parse')
const isBefore = require('date-fns/is_before')
const addDays = require('date-fns/add_days')
const fs = require('fs-extra')
const path = require('path')
const execa = require('execa')

const MYSQL_USER = process.env.MYSQL_USER || 'root'
const MYSQL_ROOT_PASSWORD = process.env.MYSQL_ROOT_PASSWORD || ''
const MYSQL_HOST = process.env.MYSQL_HOST || '127.0.0.1'
const MYSQL_PORT = process.env.MYSQL_PORT || '3306'

const AWS_ACCESS_KEY_ID = 'X'
const AWS_SECRET_ACCESS_KEY = 'X'
const S3_BACKUP_PATH = 's3://x/foo/bar'

const DATA_DIRECTORY = '/var/lib/mysql'
const BACKUP_DIRECTORY = '/backup'

const BACKUP_NAME=format(new Date(), 'YYYY-MM-DD')

const xtrabackupBaseArgs = [
  `--datadir=${DATA_DIRECTORY}`,
  `--user=${MYSQL_USER}`,
  `--password=${MYSQL_ROOT_PASSWORD}`,
  `--host=${MYSQL_HOST}`,
  `--port=${MYSQL_PORT}`
]

run()

async function run () {
  console.time('job')
  await fs.ensureDir(BACKUP_DIRECTORY)

  await setupGCloud()
  await runBackup()
  await runClean()
  await runSync()

  console.log('Job finished!')
  console.timeEnd('job')
}

async function runBackup () {
  const currentBackupDirectory = path.join(BACKUP_DIRECTORY, BACKUP_NAME)
  await fs.ensureDir(currentBackupDirectory)

  const fullBackupDirectory = path.join(currentBackupDirectory, 'full')
  const fullBackupExists = await fs.pathExists(fullBackupDirectory)

  const lastIncBackup = await findIncrementalLastBackup(currentBackupDirectory)
  const newIncrementalBackupDirectory = path.join(currentBackupDirectory, 'inc-' + format(new Date(), 'HH-mm-ss'))

  if (lastIncBackup) {
    console.log('Found a previous incremental backup: ' + lastIncBackup)
    console.log('Start incremental backup in: ' + newIncrementalBackupDirectory)
    await xtrabackup([
      `--backup`,
      `--target-dir=${newIncrementalBackupDirectory}`,
      `--incremental-basedir=${lastIncBackup}`
    ])
  } else if (fullBackupExists) {
    console.log('Found full backup: ' + fullBackupDirectory)
    console.log('Start incremental backup in: ' + newIncrementalBackupDirectory)
    await xtrabackup([
      `--backup`,
      `--target-dir=${newIncrementalBackupDirectory}`,
      `--incremental-basedir=${fullBackupDirectory}`
    ])
  } else {
    console.log('Could not find last full backup.')
    console.log('Start full backup in: ' + fullBackupDirectory)
    await xtrabackup([
      `--backup`,
      `--target-dir=${fullBackupDirectory}`
    ])
  }
}

async function runClean () {
  const maxDate = addDays(new Date(), -2)

  const files = (await fs.readdir(BACKUP_DIRECTORY))
    .map(file => [file, parse(file)])
    .filter(([ file, date ]) => !isNaN(date))
    .filter(([ file, date ]) => isBefore(date, maxDate))
    .map(([ file, date ]) => file)

  if (!files.length) {
    console.log('There no previous backup to clean.')
  }

  await Promise.all(files.map(async file => {
    const dirPath = path.join(BACKUP_DIRECTORY, file)

    console.log('Remove previous backup: ' + dirPath)
    await fs.remove(dirPath)
  }))
}

async function runSync () {
  await execa('gsutil', [
    'rsync',
    '-d',
    '-r',
    BACKUP_DIRECTORY,
    GCLOUD_BACKUP_PATH
  ], { stdio: 'inherit' })
}

async function setupGCloud () {
  const keyFile = '/tmp/gcloud-service-account.key'
  await fs.writeFile(keyFile, Buffer.from(GCLOUD_SERVICE_ACCOUNT_KEY, 'base64').toString())
  await execa('gcloud', [ 'auth', 'activate-service-account', `--key-file=${keyFile}` ])
  await fs.remove(keyFile)
}

async function findIncrementalLastBackup (directoryPath) {
  if (!await fs.pathExists(directoryPath)) {
    return
  }
  const files = (await fs.readdir(directoryPath))
    .filter(file => file.match(/^inc-/))
  if (!files.length) {
    return
  }
  return path.join(directoryPath, files[files.length - 1])
}

async function xtrabackup (args) {
  return await execa('xtrabackup', [ ...args, ...xtrabackupBaseArgs ], { stdio: 'inherit' })
}
